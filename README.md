# ğŸ§  NewsNinja â€“ AI Journalist using MCP, RAG & TTS

**NewsNinja** is your personal AI-powered journalist that fetches, summarizes, and narrates the latest from premium **News** sources and **Reddit** discussions. It combines web scraping via **BrightData MCP**, summarization via **Anthropic Claude / Ollama**, and **Text-to-Speech** generation using ElevenLabs or gTTS.

## ğŸ“Œ Key Features

- ğŸ” Scrape real-time news from Google News using BrightData MCP
- ğŸ“‘ Analyze Reddit reactions using LangChain agents
- ğŸ§  Summarize content using Anthropic Claude / Ollama
- ğŸ™ï¸ Generate human-like audio summaries (via ElevenLabs or gTTS)
- âš¡ Fully modular backend + Streamlit-based frontend
- ğŸ”„ Uses Model Context Protocol (MCP) for tool chaining

---

## ğŸ“‚ Project Structure

| File/Folder                | Description                                      |
|----------------------------|--------------------------------------------------|
| ğŸ“ `NewsNinja/`            | Root project directory                           |
| â”œâ”€â”€ `frontend.py`          | Streamlit UI for topic selection + playback      |
| â”œâ”€â”€ `news_scraper.py`      | Scrapes Google News results via BrightData MCP   |
| â”œâ”€â”€ `reddit_scraper.py`    | Scrapes Reddit and analyzes sentiment            |
| â”œâ”€â”€ `models.py`            | Pydantic model for API validation                |
| â”œâ”€â”€ `utils.py`             | Utility functions for scraping, TTS, summarizing |
| â”œâ”€â”€ `Pipfile` / `Pipfile.lock` | Pipenv environment files                  |
| â”œâ”€â”€ `README.md`            | Project documentation                            |
| â”œâ”€â”€ `.env` (not included)  | Environment variables                            |
| â””â”€â”€ `audio/`               | Generated audio files                            |

---

## ğŸ§± Core Technologies

- **Streamlit** â€“ UI for topic input and playback
- **FastAPI** â€“ (optional) Backend API
- **BrightData MCP** â€“ Browser-based scraping
- **LangChain Agents** â€“ Tool chaining and summarization
- **Anthropic Claude** â€“ Summarization LLM
- **Ollama** â€“ Local LLM summarizer
- **ElevenLabs / gTTS** â€“ Text-to-speech generation
- **Python Async + Tenacity** â€“ Retry logic for scraping

---

## ğŸ“ Architecture

### Phase 1 â€“ Frontend Interaction

- Select topic and source (News, Reddit, or Both)
- Click â€œGenerate Summaryâ€
- Streamlit sends POST request to backend

### Phase 2 â€“ Backend Data Aggregation

- `news_scraper.py`: scrapes headlines via MCP + summarizes
- `reddit_scraper.py`: gathers discussions + sentiment analysis
- `utils.py`: combines content into broadcast format
- Generates TTS audio with ElevenLabs or fallback to gTTS

### Phase 3 â€“ Audio Delivery

- Streamlit receives and plays audio
- Option to download `.mp3` file
  ![Screenshot 2025-06-17 233235](https://github.com/user-attachments/assets/2e204b48-e969-4616-a703-e7fd389bb5bb)




## âš™ï¸ Setup Guide (Quick Start)

### ğŸ”¹ Option 1: Pipenv (Recommended)

```bash
pip install pipenv
pipenv install
pipenv shell
```
ğŸ”¹ Option 2: pip + virtualenv
```bash
pip install virtualenv
virtualenv venv

# Activate the environment
# On Windows:
venv\Scripts\activate

# On macOS/Linux:
source venv/bin/activate

pip install -r requirements.txt
```
ğŸ”¹ Option 3: Conda

```bash
conda create -n newsninja python=3.13
conda activate newsninja
pip install -r requirements.txt
```
Fill in your API keys inside .env:
```bash

BRIGHTDATA_API_KEY=your_key_here
WEB_UNLOCKER_ZONE=your_zone
ELEVENLABS_API_KEY=your_key_here
ANTHROPIC_API_KEY=your_key_here
```

ğŸš€ Run the Application
ğŸ“¦ Full Pipeline (Frontend + Backend)
Use two terminals:

Terminal 1: Backend

```bash

pipenv run python backend.py
```
Terminal 2: Frontend

```bash

pipenv run streamlit run frontend.py
```
â–¶ï¸ Run Components Individually
ğŸ§© Frontend Only
```bash

streamlit run frontend.py
```
ğŸ“° News Scraper (Standalone)
```bash

pipenv run python news_scraper.py
```
ğŸ§µ Reddit Scraper (Standalone)
```bash

pipenv run python reddit_scraper.py
```

ğŸ§ª Example Use Case
---
1. Launch the app

2. Enter topic: Artificial Intelligence

3. Select data source: Both

4. Click ğŸš€ Generate Summary

âœ… The app will:
---

ğŸ” Scrape Google News + Reddit

ğŸ§  Summarize content using Anthropic or Ollama

ğŸ™ï¸ Generate and stream an audio report

ğŸ“˜ What is MCP?
---
Model Context Protocol (MCP) is an open standard that allows LLMs to securely interact with external tools and data (e.g., scrapers, APIs).

In this project, MCP helps with:

Scraping dynamic websites

Emulating browsers to bypass anti-bot tools

Allowing the AI to â€œactâ€ and retrieve real-world content


ğŸ“š References with Links
---
BrightData MCP (Mobile Carrier Proxy / Data Platform)

ğŸ”— https://brightdata.com

LangChain (Framework for building LLM applications)

ğŸ”— https://www.langchain.com



Anthropic Claude (AI Assistant by Anthropic)

ğŸ”— https://www.anthropic.com/index/claude

Ollama (Run large language models locally)

ğŸ”— https://ollama.com

ElevenLabs (AI Voice Generation & Text-to-Speech)

ğŸ”— https://www.elevenlabs.io

Streamlit (Framework to create data web apps in Python)

ğŸ”— https://streamlit.io



ğŸ“„ License
---
MIT License â€“ feel free to use, modify, and distribute with credit.
